{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk1dWTkz8bB9S5j95jADJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arpitsinghvampire/PyTorch_codes/blob/main/INTRODUCTION_TO_PYTORCH_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqwAHWFX8_49",
        "outputId": "857fae8e-6c52-42de-a0f9-40a833137da3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1, -1],\n",
              "        [-2, -2]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.tensor([[-1,-1] , [-2,-2]]) #two dimensional vector as the tensor\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(7) #scalara as the tensor\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz2KmjRP9fpa",
        "outputId": "ae806c8c-eefe-496e-a7c7-afd01a2fdfd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets create a tensor of a particular shape\n",
        "dimensional_array = torch.tensor((2,4))\n",
        "print(dimensional_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJFBuVgA9ftT",
        "outputId": "576792cc-3ec7-4b32-ed52-48af1cc734f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM HERE WE  START WITH THE PYTORCH TUTORIAL"
      ],
      "metadata": {
        "id": "mEjfHIca_Gbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from here we start with the data  from the pytorch tutorial\n",
        "#IMPORT THE NECESSARY THE LIBRARIES\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n"
      ],
      "metadata": {
        "id": "OPdHL8QR9fwb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we import the data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    transform = ToTensor(),\n",
        "    download = \"False\",\n",
        "    train = True,\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    transform = ToTensor(),\n",
        "    download = \"False\",\n",
        "    train = False,\n",
        ")"
      ],
      "metadata": {
        "id": "44pyc38k9fzj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxlL6Gy39f2a",
        "outputId": "bf85e284-b878-47d5-a9ad-9c94b9f44aa2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets create the data loader\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_data , batch_size = batch_size , shuffle = True)\n",
        "test_dataloader = DataLoader(test_data ,batch_size = batch_size, shuffle = True )\n",
        "\n",
        "#now lets check for the shape of the train data loader\n",
        "for X,y in train_dataloader:\n",
        "  print(f\"THE SHAPE OF THE INPUT TO THE MODEL SHOULD BE \" , X.shape)\n",
        "  print(f\" THE SHAPE OF THE OUTPUT TO THE MODEL SHOULD BE \" , y.shape)\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akS94f8R9f5i",
        "outputId": "0f601833-f5f6-4867-a7b3-c38eefcc3d2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE SHAPE OF THE INPUT TO THE MODEL SHOULD BE  torch.Size([64, 1, 28, 28])\n",
            " THE SHAPE OF THE OUTPUT TO THE MODEL SHOULD BE  torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets check for the accelerator if it present\n",
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else 'cpu'\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "#now lets define the model\n",
        "#always inherits from the nn.Module\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten() #this flattens the data which in our case is 28x28\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28 , 512) ,\n",
        "        nn.ReLU() ,\n",
        "        nn.Linear(512 , 512),\n",
        "        nn.ReLU() ,\n",
        "        nn.Linear(512 , 10) #Linear takes in parameter as input_channels , output _channels\n",
        "        #this has created the model , lets now take it a notch up and fit the data to the model\n",
        "\n",
        "    )\n",
        "  def forward(self , x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear_relu_stack(x)\n",
        "    return x\n",
        "    #this returns  x after performing the above operations\n",
        "\n",
        "neural_net = NeuralNetwork().to(device) #transfer everything to the required device\n",
        "print(neural_net.parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1f-OoBTFci4",
        "outputId": "dceb40b0-06ab-49ff-8218-cd0bdd7ab41f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n",
            "<bound method Module.parameters of NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we need to also train the model  for this we use the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(neural_net.parameters() , lr = 1e-3)\n",
        "\n",
        "#now lets train the model\n",
        "def train(dataloader ,model , loss_fn ,optimizer ):\n",
        "  size = len(dataloader.dataset) #dataloader.dataset just returns  the  original dataset from ehich you set the  dataloader\n",
        "  #now we train the model\n",
        "  for batch , (X,y) in enumerate(dataloader):\n",
        "    #transfer the things to the required device\n",
        "    prediction = model(X) #this gives us the preediction of the model\n",
        "    #after getting the prediction ,lets now get the loss and then train the model\n",
        "    loss = loss_fn(prediction , y)\n",
        "    #now for making the optimiser step lets fir make the gradient as 0\n",
        "    optimizer.zero_grad()\n",
        "    #now move backward to get the gradients\n",
        "    loss.backward()\n",
        "    #after getting the loss backward , now lets  use the optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #now we print the  metrics we recieved after every epoch\n",
        "    if batch % 100 == 0:\n",
        "      loss , current = loss.item() , (batch) * len(X)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader , model , loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  #now we put the model in the eval model\n",
        "  model.eval()\n",
        "  test_loss , correct = 0,0\n",
        "  with torch.no_grad(): # for the testing part , the gradient need not be calculated\n",
        "    for X,y in dataloader:\n",
        "      X , y = X.to(device) , y.to(device)\n",
        "      prediction = model(X)\n",
        "      test_loss += loss_fn(prediction , y).item()\n",
        "  test_loss = test_loss / num_batches\n",
        "  print(f\"Average loss is {test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "32dGMtxmLrIX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs  = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(train_dataloader , neural_net , loss_fn , optimizer)\n",
        "  test(test_dataloader , neural_net , loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXL7oC0tFcm9",
        "outputId": "cc3c63ab-11de-4529-d71d-2db31145bfcc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.847936  [    0/60000]\n",
            "loss: 0.830036  [ 6400/60000]\n",
            "loss: 0.750630  [12800/60000]\n",
            "loss: 0.771198  [19200/60000]\n",
            "loss: 0.728050  [25600/60000]\n",
            "loss: 0.752310  [32000/60000]\n",
            "loss: 0.771431  [38400/60000]\n",
            "loss: 0.786946  [44800/60000]\n",
            "loss: 0.636334  [51200/60000]\n",
            "loss: 0.717894  [57600/60000]\n",
            "Average loss is 0.763005 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.895226  [    0/60000]\n",
            "loss: 0.865263  [ 6400/60000]\n",
            "loss: 0.712641  [12800/60000]\n",
            "loss: 0.941781  [19200/60000]\n",
            "loss: 0.834143  [25600/60000]\n",
            "loss: 0.648712  [32000/60000]\n",
            "loss: 0.718914  [38400/60000]\n",
            "loss: 0.878667  [44800/60000]\n",
            "loss: 0.682874  [51200/60000]\n",
            "loss: 0.822990  [57600/60000]\n",
            "Average loss is 0.741653 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.728123  [    0/60000]\n",
            "loss: 0.855000  [ 6400/60000]\n",
            "loss: 0.656147  [12800/60000]\n",
            "loss: 0.571629  [19200/60000]\n",
            "loss: 0.768432  [25600/60000]\n",
            "loss: 0.719920  [32000/60000]\n",
            "loss: 0.709778  [38400/60000]\n",
            "loss: 0.704913  [44800/60000]\n",
            "loss: 0.646740  [51200/60000]\n",
            "loss: 0.789348  [57600/60000]\n",
            "Average loss is 0.720597 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.634809  [    0/60000]\n",
            "loss: 0.722947  [ 6400/60000]\n",
            "loss: 0.789360  [12800/60000]\n",
            "loss: 0.616977  [19200/60000]\n",
            "loss: 0.664458  [25600/60000]\n",
            "loss: 0.585728  [32000/60000]\n",
            "loss: 0.765938  [38400/60000]\n",
            "loss: 0.629917  [44800/60000]\n",
            "loss: 0.773860  [51200/60000]\n",
            "loss: 0.815378  [57600/60000]\n",
            "Average loss is 0.703971 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.682619  [    0/60000]\n",
            "loss: 0.750685  [ 6400/60000]\n",
            "loss: 0.814023  [12800/60000]\n",
            "loss: 0.789855  [19200/60000]\n",
            "loss: 0.778769  [25600/60000]\n",
            "loss: 0.717142  [32000/60000]\n",
            "loss: 0.725457  [38400/60000]\n",
            "loss: 0.695950  [44800/60000]\n",
            "loss: 0.560526  [51200/60000]\n",
            "loss: 0.687659  [57600/60000]\n",
            "Average loss is 0.688904 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.725599  [    0/60000]\n",
            "loss: 0.757447  [ 6400/60000]\n",
            "loss: 0.677589  [12800/60000]\n",
            "loss: 0.652148  [19200/60000]\n",
            "loss: 0.576933  [25600/60000]\n",
            "loss: 0.767838  [32000/60000]\n",
            "loss: 0.702818  [38400/60000]\n",
            "loss: 0.684737  [44800/60000]\n",
            "loss: 0.658575  [51200/60000]\n",
            "loss: 0.682100  [57600/60000]\n",
            "Average loss is 0.672640 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.720767  [    0/60000]\n",
            "loss: 0.719698  [ 6400/60000]\n",
            "loss: 0.883589  [12800/60000]\n",
            "loss: 0.811179  [19200/60000]\n",
            "loss: 0.619843  [25600/60000]\n",
            "loss: 0.741546  [32000/60000]\n",
            "loss: 0.634660  [38400/60000]\n",
            "loss: 0.521232  [44800/60000]\n",
            "loss: 0.584477  [51200/60000]\n",
            "loss: 0.561927  [57600/60000]\n",
            "Average loss is 0.658704 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.561205  [    0/60000]\n",
            "loss: 0.546493  [ 6400/60000]\n",
            "loss: 0.700124  [12800/60000]\n",
            "loss: 0.557008  [19200/60000]\n",
            "loss: 0.502280  [25600/60000]\n",
            "loss: 0.435689  [32000/60000]\n",
            "loss: 0.580569  [38400/60000]\n",
            "loss: 0.627941  [44800/60000]\n",
            "loss: 0.719463  [51200/60000]\n",
            "loss: 0.665142  [57600/60000]\n",
            "Average loss is 0.646147 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.650950  [    0/60000]\n",
            "loss: 0.679399  [ 6400/60000]\n",
            "loss: 0.459415  [12800/60000]\n",
            "loss: 0.607529  [19200/60000]\n",
            "loss: 0.470948  [25600/60000]\n",
            "loss: 0.602528  [32000/60000]\n",
            "loss: 0.479244  [38400/60000]\n",
            "loss: 0.671688  [44800/60000]\n",
            "loss: 0.595732  [51200/60000]\n",
            "loss: 0.654872  [57600/60000]\n",
            "Average loss is 0.634373 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.666005  [    0/60000]\n",
            "loss: 0.464721  [ 6400/60000]\n",
            "loss: 0.701871  [12800/60000]\n",
            "loss: 0.495673  [19200/60000]\n",
            "loss: 0.563005  [25600/60000]\n",
            "loss: 0.519972  [32000/60000]\n",
            "loss: 0.661568  [38400/60000]\n",
            "loss: 0.850280  [44800/60000]\n",
            "loss: 0.520043  [51200/60000]\n",
            "loss: 0.539363  [57600/60000]\n",
            "Average loss is 0.623080 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets save the model\n",
        "torch.save(neural_net.state_dict() , \"/content/data/FashionMNIST/neural_network_model1\")\n",
        "print(f\"Saved PyTorch Model State to {\"/content/data/FashionMNIST/neural_network_model1\"}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08y7vX3QFcsc",
        "outputId": "0fcdd581-edf8-490d-9998-b976477b7520"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to /content/data/FashionMNIST/neural_network_model1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now lets load the model again to ensure that everything is okay\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/data/FashionMNIST/neural_network_model1\" , weights_only = True))\n",
        "#if all the keys match perfectly that means that the model was successfully loaded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22lFt3p-Fc0z",
        "outputId": "20147f9f-9309-420c-ee1f-eae4cf0bd8ec"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}